---
name: initializer-agent
description: Use the Initializer Agent pattern to setup verification infrastructure BEFORE writing any implementation code. Use when starting new features, onboarding to unfamiliar codebases, or when previous implementations failed verification. The agent's first job is writing setup_verification.sh, not feature code.
---

# Initializer Agent Skill
## Setup Verification Before Implementation

**Source**: Anthropic Research on Long-Running Agent Harnesses
**Rule**: Never start coding with a generic prompt. Setup verification first.

---

## The Pattern

### Traditional (Wrong) Approach
```
1. User: "Implement user authentication"
2. Agent: Writes auth code
3. Agent: Claims "done"
4. Reality: Code doesn't compile, tests don't exist
```

### Initializer Agent (Correct) Approach
```
1. User: "Implement user authentication"
2. Agent (Initializer Role): 
   - Analyzes what verification is needed
   - Writes setup_verification.sh
   - Runs baseline verification (should pass)
3. Agent (Worker Role):
   - Writes canary test (should fail)
   - Implements code
   - Runs verification (should pass)
4. Reality: Verified working code
```

---

## The Initializer Turn

Before ANY implementation, execute this specialized turn:

### Step 1: Analyze Verification Requirements

```markdown
## Verification Analysis for: [Feature Name]

### Files That Will Be Modified
- src/auth/login.ts
- src/auth/types.ts
- tests/auth/login.test.ts

### Existing Verification Available
- [ ] Linter configured: YES/NO
- [ ] Type checking: YES/NO
- [ ] Test framework: YES/NO
- [ ] Relevant tests exist: YES/NO

### Verification Gaps
- [List what's missing]
```

### Step 2: Write setup_verification.sh

```bash
#!/bin/bash
# setup_verification.sh - Run BEFORE implementation
# Generated by Initializer Agent for: [Feature Name]

set -e
echo "üîç Running baseline verification..."

# Step 1: Ensure dependencies
echo "Checking dependencies..."
npm install 2>/dev/null || pip install -r requirements.txt 2>/dev/null

# Step 2: Run linter on files we'll touch
echo "Linting target files..."
npx eslint src/auth/*.ts --max-warnings=0

# Step 3: Type check
echo "Type checking..."
npx tsc --noEmit

# Step 4: Run existing tests for this area
echo "Running existing tests..."
npm test -- --testPathPattern="auth" --passWithNoTests

# Step 5: Verify baseline passes
echo ""
echo "================================"
echo "‚úÖ BASELINE VERIFICATION PASSED"
echo "Ready for implementation"
echo "================================"
```

### Step 3: Run Baseline

```bash
bash setup_verification.sh
```

**CRITICAL**: If baseline fails, fix environment before implementing features.

---

## The Canary Test Pattern

After baseline passes, write a test that SHOULD FAIL:

```typescript
// tests/auth/login.test.ts - Canary Test

describe('User Authentication', () => {
  it('should authenticate valid user credentials', async () => {
    // This test should FAIL until we implement the feature
    const result = await authenticateUser('test@example.com', 'password123');
    
    expect(result.success).toBe(true);
    expect(result.token).toBeDefined();
    expect(result.user.email).toBe('test@example.com');
  });
  
  it('should reject invalid credentials', async () => {
    const result = await authenticateUser('test@example.com', 'wrongpassword');
    
    expect(result.success).toBe(false);
    expect(result.error).toBe('INVALID_CREDENTIALS');
  });
});
```

**Verify it fails**:
```bash
npm test -- --testPathPattern="login"
# Expected: FAIL (function not implemented)
```

---

## The Full Initializer Protocol

### Phase 1: Initialization (Separate Session)

```markdown
# INITIALIZER AGENT PROMPT

You are an Initializer Agent. Your ONLY job is to prepare the 
verification infrastructure. You will NOT write feature code.

Task: [Feature description]

## Your Deliverables

1. `setup_verification.sh` - Baseline verification script
2. `canary_test.[ext]` - Test that should fail now, pass after implementation
3. `implementation_scope.md` - Exact files to be modified

## Constraints

- Do NOT write implementation code
- Do NOT modify production files
- ONLY create verification infrastructure
- VERIFY baseline passes before finishing

## Output Format

```
INITIALIZER COMPLETE
Baseline Status: PASSING
Canary Test Status: FAILING (expected)
Implementation Scope: [list of files]
Ready for Worker Agent: YES/NO
```
```

### Phase 2: Implementation (Fresh Session)

```markdown
# WORKER AGENT PROMPT

You are a Worker Agent. The Initializer has prepared your environment.

## Pre-Loaded Context
- setup_verification.sh (baseline passes)
- canary_test exists (currently failing)
- Implementation scope: [files from initializer]

## Your Task

1. Read the canary test to understand requirements
2. Implement code to make the canary test pass
3. Run full verification before claiming done

## Success Criteria

```bash
bash setup_verification.sh  # Must still pass
npm test -- --testPathPattern="[feature]"  # Must now pass
```

Do NOT claim completion until verification passes.
```

---

## Integration with Domain Memory

### features.json Enhancement

```json
{
  "features": [
    {
      "id": "F001",
      "description": "User authentication",
      "status": "initialized",
      "initialization": {
        "completed": true,
        "baseline_passing": true,
        "canary_test_path": "tests/auth/login.test.ts",
        "canary_test_failing": true,
        "verification_script": ".claude/verify_F001.sh",
        "implementation_scope": [
          "src/auth/login.ts",
          "src/auth/types.ts"
        ]
      }
    }
  ]
}
```

### Status Flow

```
"todo" 
  ‚Üí Initializer runs
"initialized" (baseline passes, canary fails)
  ‚Üí Worker implements
"failing" (canary still fails or baseline breaks)
  ‚Üí Worker debugs
"passing" (baseline passes AND canary passes)
```

---

## Quick Reference

### Before ANY Implementation

```bash
# 1. Run initializer prompt
"You are an Initializer Agent. Prepare verification for: [feature]"

# 2. Verify baseline
bash setup_verification.sh
# Must output: ‚úÖ BASELINE VERIFICATION PASSED

# 3. Verify canary fails
npm test -- --testPathPattern="[feature]"
# Must output: FAIL (this is expected)

# 4. Only THEN start implementation
"You are a Worker Agent. Implement [feature] to pass the canary test."
```

### After Implementation

```bash
# 1. Verify baseline still passes
bash setup_verification.sh
# Must output: ‚úÖ BASELINE VERIFICATION PASSED

# 2. Verify canary now passes
npm test -- --testPathPattern="[feature]"
# Must output: PASS

# 3. Update features.json
# status: "passing"
```

---

## Common Mistakes

```
‚ùå WRONG: "Implement auth" ‚Üí Agent writes code ‚Üí Claims done
‚ùå WRONG: "Write tests after code" ‚Üí Tests written to match buggy code
‚ùå WRONG: "Skip baseline" ‚Üí New code breaks existing functionality

‚úÖ RIGHT: Baseline first ‚Üí Canary test ‚Üí Implementation ‚Üí Verification
```

---

## Template: setup_verification.sh

```bash
#!/bin/bash
# setup_verification.sh
# Feature: [FEATURE_NAME]
# Generated: [DATE]

set -e

FEATURE_ID="[F001]"
TARGET_FILES=(
    "src/path/to/file1.ts"
    "src/path/to/file2.ts"
)

echo "üîç Verification for $FEATURE_ID"
echo "================================"

# 1. Dependencies
echo "[1/5] Checking dependencies..."
npm install --silent

# 2. Lint target files
echo "[2/5] Linting..."
for file in "${TARGET_FILES[@]}"; do
    if [ -f "$file" ]; then
        npx eslint "$file" --max-warnings=0
    fi
done

# 3. Type check
echo "[3/5] Type checking..."
npx tsc --noEmit

# 4. Existing tests
echo "[4/5] Running existing tests..."
npm test -- --passWithNoTests --silent

# 5. Slop tests
echo "[5/5] Slop tests..."
bash .claude/slop-tests.sh || true

echo ""
echo "================================"
echo "‚úÖ BASELINE PASSED - Ready for implementation"
```

---

*This skill ensures agents never start coding until they can prove their work.*
